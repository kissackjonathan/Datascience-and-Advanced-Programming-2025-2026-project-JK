"""
Political Stability Observatory - Interactive Dashboard
"""

import json
import os
import sys
from contextlib import contextmanager
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ============================================================================
# UTILITY: SUPPRESS STDOUT/STDERR FOR STREAMLIT COMPATIBILITY
# ============================================================================


@contextmanager
def suppress_stdout_stderr():
    """
    Context manager to suppress stdout and stderr.
    Prevents I/O errors in Streamlit when GridSearchCV tries to print.
    """
    # Save original stdout/stderr
    old_stdout = sys.stdout
    old_stderr = sys.stderr

    try:
        # Redirect to devnull
        with open(os.devnull, "w") as devnull:
            sys.stdout = devnull
            sys.stderr = devnull
            yield
    finally:
        # Restore original stdout/stderr
        sys.stdout = old_stdout
        sys.stderr = old_stderr


# Page configuration
st.set_page_config(
    page_title="Political Stability Observatory",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ============================================================================
# SESSION STATE INITIALIZATION
# ============================================================================

# Initialize session state for workflow tracking
if "workflow_step" not in st.session_state:
    st.session_state.workflow_step = (
        0  # 0: not started, 1: data loaded, 2: models trained, 3: models tested
    )

if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False

if "models_trained" not in st.session_state:
    st.session_state.models_trained = False

if "models_tested" not in st.session_state:
    st.session_state.models_tested = False

# Data storage in session state
if "X_train" not in st.session_state:
    st.session_state.X_train = None
if "X_test" not in st.session_state:
    st.session_state.X_test = None
if "y_train" not in st.session_state:
    st.session_state.y_train = None
if "y_test" not in st.session_state:
    st.session_state.y_test = None
if "feature_names" not in st.session_state:
    st.session_state.feature_names = None

# Model results storage
if "trained_models" not in st.session_state:
    st.session_state.trained_models = {}
if "training_results" not in st.session_state:
    st.session_state.training_results = None
if "test_results" not in st.session_state:
    st.session_state.test_results = None

# Custom CSS
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .info-box {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #2196F3;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
    }
    .action-button {
        width: 100%;
        padding: 1rem;
        font-size: 1.1rem;
        font-weight: bold;
        margin: 0.5rem 0;
    }
</style>
""",
    unsafe_allow_html=True,
)

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================


def get_project_paths():
    """Get all project paths"""
    base = Path(__file__).parent.parent  # Go up to project root
    return {
        "data_raw": base / "data" / "raw",
        "data_processed": base / "data" / "processed",
        "models": base / "models",
        "results": base / "results",
        "figures": base / "results" / "figures",
    }


# ============================================================================
# DATA LOADING
# ============================================================================


@st.cache_data
def load_data():
    """Load all necessary data"""
    try:
        # Try to load full_data.csv first (generated by Action 1)
        # Use absolute path from project root
        data_path = project_root / "data" / "processed" / "full_data.csv"
        df = pd.read_csv(data_path)
        return df
    except Exception as e:
        # If full_data.csv doesn't exist, return None
        # User will need to run Action 1 in Project page first
        return None


@st.cache_data
def load_map_data():
    """Load data for world map - requires running Action 1 first to process raw data"""
    try:
        # Load the processed file (created by Action 1: Run Data Preparation)
        # Use absolute path from project root
        data_path = project_root / "data" / "processed" / "full_data.csv"
        df = pd.read_csv(data_path)
        return df
    except FileNotFoundError:
        # File doesn't exist - user needs to run Action 1 first
        return None
    except Exception as e:
        # Other error
        return None


df = load_data()
df_map = load_map_data()

# ============================================================================
# SIDEBAR NAVIGATION
# ============================================================================

st.sidebar.markdown("#  Political Stability")
st.sidebar.markdown("## Observatory")
st.sidebar.markdown("---")

page = st.sidebar.radio("Navigation", [" Home", " Explorer", " Project"], index=0)

st.sidebar.markdown("---")
st.sidebar.markdown("### About")
st.sidebar.info(
    """
    **Data Science & Advanced Programming**
    Master's Project 2025-2026

    **Dataset**: 1996-2023
    **Countries**: 166
    **Models**: 5 ML algorithms
    """
)

# ============================================================================
# PAGE 1: HOME
# ============================================================================

if page == " Home":
    st.markdown(
        "<h1 class='main-header'> Political Stability Observatory</h1>",
        unsafe_allow_html=True,
    )
    st.markdown("---")

    # Introduction
    st.markdown(
        """
    ### Welcome to the Political Stability Observatory

    This interactive dashboard provides **machine learning predictions** for political stability across 166 countries,
    spanning from 1996 to 2023. Our analysis leverages **8 advanced ML algorithms** to forecast stability using
    economic, governance, and development indicators.
    """
    )

    # KPIs
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if df_map is not None and "Country Name" in df_map.columns:
            value = df_map["Country Name"].nunique()
        else:
            value = "N/A"
        st.metric(label=" Countries Analyzed", value=value)

    with col2:
        if df_map is not None and "Year" in df_map.columns:
            value = f"{int(df_map['Year'].min())}-{int(df_map['Year'].max())}"
        else:
            value = "N/A"
        st.metric(label=" Time Period", value=value)

    with col3:
        st.metric(label=" Best Model", value="Random Forest", delta="77.26% R^2")

    with col4:
        value = f"{len(df_map):,}" if df_map is not None else "N/A"
        st.metric(label=" Total Observations", value=value)

    st.markdown("---")

    # Model Performance Comparison
    st.markdown("###  Model Performance Comparison")

    model_performance = {
        "Model": ["Random Forest", "XGBoost", "MLP", "KNN", "SVR"],
        "Test R^2": [0.7726, 0.7204, 0.6984, 0.6869, 0.6293],
        "Test RMSE": [0.4521, 0.5015, 0.5194, 0.5292, 0.5758],
    }

    perf_df = pd.DataFrame(model_performance)

    col1, col2 = st.columns([2, 1])

    with col1:
        fig = px.bar(
            perf_df,
            x="Model",
            y="Test R^2",
            title="Model Performance (R^2 Score)",
            color="Test R^2",
            color_continuous_scale="Blues",
            text="Test R^2",
        )
        fig.update_traces(texttemplate="%{text:.2%}", textposition="outside")
        fig.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown("###  Top 3 Models")
        st.markdown(
            """
        **1. Random Forest**
        R^2 = 77.26%
        RMSE = 0.45

        **2. XGBoost**
        R^2 = 72.04%
        RMSE = 0.50

        **3. MLP Neural Network**
        R^2 = 69.84%
        RMSE = 0.52
        """
        )

    st.markdown("---")

    # World Map
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown("###  Global Political Stability (Latest Year)")
    with col2:
        if st.button(" Reload Data", key="reload_data"):
            st.cache_data.clear()
            st.rerun()

    # Check if data is available with minimum required columns
    required_cols = ["Country Name", "Year", "political_stability"]

    if df_map is not None and all(col in df_map.columns for col in required_cols):
        # Get latest year data
        latest_year = int(df_map["Year"].max())
        df_latest = df_map[df_map["Year"] == latest_year].copy()

        # Year slider
        selected_year = st.slider(
            "Select Year",
            min_value=int(df_map["Year"].min()),
            max_value=int(df_map["Year"].max()),
            value=latest_year,
            step=1,
        )

        df_selected = df_map[df_map["Year"] == selected_year].copy()

        # Build hover_data dynamically based on available columns
        hover_data = {"political_stability": ":.3f"}
        if "Country Code" in df_selected.columns:
            hover_data["Country Code"] = False
        if "gdp_per_capita" in df_selected.columns:
            hover_data["gdp_per_capita"] = ":.0f"
        if "hdi" in df_selected.columns:
            hover_data["hdi"] = ":.3f"
        if "unemployment" in df_selected.columns:
            hover_data["unemployment"] = ":.2f"

        # Create choropleth map - use Country Code if available, otherwise use Country Name
        if "Country Code" in df_selected.columns:
            fig = px.choropleth(
                df_selected,
                locations="Country Code",
                color="political_stability",
                hover_name="Country Name",
                hover_data=hover_data,
                color_continuous_scale="RdYlGn",
                range_color=[-3, 2],
                title=f"Political Stability Index - {selected_year}",
                labels={
                    "political_stability": "Stability Score",
                    "gdp_per_capita": "GDP per Capita",
                    "hdi": "HDI",
                    "unemployment": "Unemployment",
                },
            )
        else:
            # Fallback: use country names (less accurate but works)
            fig = px.choropleth(
                df_selected,
                locations="Country Name",
                locationmode="country names",
                color="political_stability",
                hover_name="Country Name",
                hover_data=hover_data,
                color_continuous_scale="RdYlGn",
                range_color=[-3, 2],
                title=f"Political Stability Index - {selected_year}",
                labels={
                    "political_stability": "Stability Score",
                    "gdp_per_capita": "GDP per Capita",
                    "hdi": "HDI",
                    "unemployment": "Unemployment",
                },
            )

        fig.update_layout(
            height=600,
            geo=dict(
                showframe=False, showcoastlines=True, projection_type="natural earth"
            ),
        )

        st.plotly_chart(fig, use_container_width=True)

        # Color scale explanation
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("**Red**: Low stability (< -1.0)")
        with col2:
            st.markdown("**Yellow**: Moderate stability (-1.0 to 0.5)")
        with col3:
            st.markdown("**Green**: High stability (> 0.5)")
    else:
        st.warning(
            """
        **Map data not available**

        The processed data file `data/processed/full_data.csv` is missing.

        **To display the map:**
        1. Go to the **Project** page (in the sidebar)
        2. Click **Action 1: Run Data Preparation**
        3. Wait for data processing to complete
        4. Come back to this page and refresh
        """
        )

# ============================================================================
# PAGE 2: EXPLORER
# ============================================================================

elif page == " Explorer":
    st.markdown(
        "<h1 class='main-header'> Country Explorer</h1>", unsafe_allow_html=True
    )
    st.markdown("---")

    if df is not None:
        # Country selector
        countries = sorted(df["Country Name"].unique())
        selected_country = st.selectbox(
            "Select a country",
            countries,
            index=countries.index("France") if "France" in countries else 0,
        )

        # Filter data for selected country
        df_country = df[df["Country Name"] == selected_country].sort_values("Year")

        # Header with current stability
        latest_stability = df_country.iloc[-1]["political_stability"]
        prev_stability = (
            df_country.iloc[-2]["political_stability"]
            if len(df_country) > 1
            else latest_stability
        )
        delta = latest_stability - prev_stability

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("Current Stability", f"{latest_stability:.3f}", f"{delta:+.3f}")

        with col2:
            st.metric("Latest Year", int(df_country["Year"].max()))

        with col3:
            trend = "Improving" if delta > 0 else "Declining" if delta < 0 else "Stable"
            st.metric("Trend", trend)

        st.markdown("---")

        # Timeline
        st.markdown("###  Stability Timeline")

        fig = go.Figure()

        fig.add_trace(
            go.Scatter(
                x=df_country["Year"],
                y=df_country["political_stability"],
                mode="lines+markers",
                name="Political Stability",
                line=dict(color="#1f77b4", width=3),
                marker=dict(size=8),
            )
        )

        fig.add_hline(
            y=0, line_dash="dash", line_color="gray", annotation_text="Neutral"
        )

        fig.update_layout(
            title=f"{selected_country} - Political Stability Over Time",
            xaxis_title="Year",
            yaxis_title="Stability Score",
            height=400,
            hovermode="x unified",
        )

        st.plotly_chart(fig, use_container_width=True)

        st.markdown("---")

        # Economic Indicators
        st.markdown("###  Economic & Governance Indicators")

        col1, col2 = st.columns(2)

        with col1:
            # GDP per capita
            fig1 = go.Figure()
            fig1.add_trace(
                go.Scatter(
                    x=df_country["Year"],
                    y=df_country["gdp_per_capita"],
                    mode="lines+markers",
                    name="GDP per capita",
                    fill="tozeroy",
                    line=dict(color="#2ecc71"),
                )
            )
            fig1.update_layout(
                title="GDP per Capita",
                xaxis_title="Year",
                yaxis_title="USD",
                height=300,
            )
            st.plotly_chart(fig1, use_container_width=True)

            # Unemployment
            fig3 = go.Figure()
            fig3.add_trace(
                go.Scatter(
                    x=df_country["Year"],
                    y=df_country["unemployment"],
                    mode="lines+markers",
                    name="Unemployment",
                    line=dict(color="#e74c3c"),
                )
            )
            fig3.update_layout(
                title="Unemployment Rate (ILO)",
                xaxis_title="Year",
                yaxis_title="%",
                height=300,
            )
            st.plotly_chart(fig3, use_container_width=True)

        with col2:
            # Rule of Law
            fig2 = go.Figure()
            fig2.add_trace(
                go.Scatter(
                    x=df_country["Year"],
                    y=df_country["rule_of_law"],
                    mode="lines+markers",
                    name="Rule of Law",
                    line=dict(color="#9b59b6"),
                )
            )
            fig2.update_layout(
                title="Rule of Law Index",
                xaxis_title="Year",
                yaxis_title="Score",
                height=300,
            )
            st.plotly_chart(fig2, use_container_width=True)

            # HDI (only if available)
            if "hdi" in df_country.columns:
                fig4 = go.Figure()
                fig4.add_trace(
                    go.Scatter(
                        x=df_country["Year"],
                        y=df_country["hdi"],
                        mode="lines+markers",
                        name="HDI",
                        fill="tozeroy",
                        line=dict(color="#3498db"),
                    )
                )
                fig4.update_layout(
                    title="Human Development Index",
                    xaxis_title="Year",
                    yaxis_title="HDI",
                    height=300,
                )
                st.plotly_chart(fig4, use_container_width=True)

        st.markdown("---")

        # Data table
        with st.expander(" View Raw Data"):
            # Only include columns that exist
            display_cols = [
                "Year",
                "political_stability",
                "gdp_per_capita",
                "gdp_growth",
                "unemployment",
                "inflation",
                "rule_of_law",
            ]
            if "hdi" in df_country.columns:
                display_cols.append("hdi")
            # Filter to only existing columns
            display_cols = [col for col in display_cols if col in df_country.columns]
            st.dataframe(
                df_country[display_cols].sort_values("Year", ascending=False),
                use_container_width=True,
                height=400,
            )

# ============================================================================
# PAGE 3: PROJECT
# ============================================================================

elif page == " Project":
    st.markdown(
        "<h1 class='main-header'> Project Workflow</h1>", unsafe_allow_html=True
    )
    st.markdown("---")

    st.markdown(
        """
    ### Complete ML Pipeline
    Run the full machine learning workflow from data preparation to model evaluation.
    **Important**: Each step must be completed in order before proceeding to the next.
    """
    )

    # Workflow Progress Indicator
    st.markdown("####  Workflow Progress")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        status = "Completed" if st.session_state.data_loaded else "Pending"
        st.markdown(f"**Step 1: Load Data**\n\n{status}")

    with col2:
        status = "Completed" if st.session_state.models_trained else "Pending"
        st.markdown(f"**Step 2: Train Models**\n\n{status}")

    with col3:
        status = "Completed" if st.session_state.models_tested else "Pending"
        st.markdown(f"**Step 3: Test Models**\n\n{status}")

    with col4:
        can_visualize = st.session_state.models_tested
        status = "Ready" if can_visualize else "Pending"
        st.markdown(f"**Step 4: Visualize**\n\n{status}")

    # Reset workflow button
    if st.session_state.workflow_step > 0:
        if st.button(" Reset Workflow", key="reset_workflow"):
            st.session_state.workflow_step = 0
            st.session_state.data_loaded = False
            st.session_state.models_trained = False
            st.session_state.models_tested = False
            st.session_state.X_train = None
            st.session_state.X_test = None
            st.session_state.y_train = None
            st.session_state.y_test = None
            st.session_state.feature_names = None
            st.session_state.trained_models = {}
            st.session_state.training_results = None
            st.session_state.test_results = None
            st.success("Workflow reset! You can start from Step 1.")
            st.rerun()

    st.markdown("---")

    # ========================================================================
    # ACTION 0: CHECK ENVIRONMENT
    # ========================================================================

    st.markdown("##  Action 0: Check Environment")
    st.markdown(
        "Verify that all required files, packages, and directories are present."
    )

    if st.button(" Run Environment Check", key="check_env", use_container_width=True):
        with st.spinner("Checking environment..."):
            from importlib.metadata import PackageNotFoundError, version

            paths = get_project_paths()

            # Check directories
            st.subheader(" Project Directories")
            dir_status = []
            for name, path in paths.items():
                exists = path.exists()
                dir_status.append(
                    {
                        "Directory": name,
                        "Path": str(path),
                        "Status": " EXISTS" if exists else " MISSING (will be created)",
                    }
                )
                if not exists:
                    path.mkdir(parents=True, exist_ok=True)

            st.dataframe(
                pd.DataFrame(dir_status), use_container_width=True, hide_index=True
            )

            # Check packages
            st.subheader(" Required Packages")
            required_packages = [
                "pandas",
                "numpy",
                "scikit-learn",
                "xgboost",
                "matplotlib",
                "seaborn",
                "streamlit",
                "plotly",
                "joblib",
            ]

            pkg_status = []
            all_ok = True
            for package in required_packages:
                try:
                    pkg_version = version(package)
                    pkg_status.append(
                        {
                            "Package": package,
                            "Version": pkg_version,
                            "Status": " Installed",
                        }
                    )
                except PackageNotFoundError:
                    pkg_status.append(
                        {
                            "Package": package,
                            "Version": "N/A",
                            "Status": " NOT INSTALLED",
                        }
                    )
                    all_ok = False

            st.dataframe(
                pd.DataFrame(pkg_status), use_container_width=True, hide_index=True
            )

            # Check raw data files
            st.subheader(" Raw Data Files")
            data_raw = paths["data_raw"]
            expected_files = [
                ("GDP per capita", [".numbers", ".csv"]),
                ("UNEMPLOYMENT_TOTAL", [".numbers", ".csv"]),
                ("inflation consumer", [".numbers", ".csv"]),
                ("hdi_data", [".xlsx"]),
            ]

            file_status = []
            for base_name, extensions in expected_files:
                found = False
                found_file = ""
                size_mb = 0
                for ext in extensions:
                    filepath = data_raw / f"{base_name}{ext}"
                    if filepath.exists():
                        size_mb = filepath.stat().st_size / (1024 * 1024)
                        found_file = f"{base_name}{ext}"
                        found = True
                        break

                file_status.append(
                    {
                        "File": base_name,
                        "Found": found_file if found else f" NOT FOUND",
                        "Size (MB)": f"{size_mb:.2f}" if found else "N/A",
                        "Status": " OK" if found else " MISSING",
                    }
                )
                if not found:
                    all_ok = False

            st.dataframe(
                pd.DataFrame(file_status), use_container_width=True, hide_index=True
            )

            # Summary
            st.markdown("---")
            if all_ok:
                st.success(" **Environment Check: ALL OK** - Ready to proceed!")
            else:
                st.error(
                    " **Environment Check: ISSUES FOUND** - Please fix missing items."
                )

    st.markdown("---")

    # ========================================================================
    # ACTION 1: RUN DATA PREPARATION
    # ========================================================================

    st.markdown("##  Action 1: Load Data")
    st.markdown("Load preprocessed training and test datasets.")

    # Always allow Action 1 (it's the first step)
    if st.button(" Load Data", key="data_prep", use_container_width=True):
        with st.spinner("Loading data..."):
            try:
                import time

                paths = get_project_paths()
                processed_dir = paths["data_processed"]

                # Check if processed files exist
                train_file = processed_dir / "train_data.csv"
                test_file = processed_dir / "test_data.csv"
                full_file = processed_dir / "full_data.csv"

                if not train_file.exists() or not test_file.exists():
                    st.error(" Processed data files not found!")
                    st.warning(
                        """
                    **Please run data preparation first:**

                    1. Open a terminal
                    2. Run: `python main/main.py`
                    3. Select option 1: "Run Data Preparation"
                    4. Come back here and click "Load Data" again
                    """
                    )
                else:
                    # Step 1: Load processed data
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text(" Step 1/3: Loading processed train data...")
                    time.sleep(0.3)
                    train_data = pd.read_csv(
                        train_file, index_col=[0, 2]
                    )  # Country Name + Year

                    # Drop Country Code if present
                    if "Country Code" in train_data.columns:
                        train_data = train_data.drop("Country Code", axis=1)
                    progress_bar.progress(25)

                    status_text.text(" Step 2/3: Loading processed test data...")
                    time.sleep(0.3)
                    test_data = pd.read_csv(
                        test_file, index_col=[0, 2]
                    )  # Country Name + Year

                    # Drop Country Code if present
                    if "Country Code" in test_data.columns:
                        test_data = test_data.drop("Country Code", axis=1)
                    progress_bar.progress(50)

                    # Step 3: Separate features and target
                    status_text.text(" Step 3/3: Preparing features and target...")
                    time.sleep(0.3)

                    X_train = train_data.drop("political_stability", axis=1)
                    y_train = train_data["political_stability"]
                    X_test = test_data.drop("political_stability", axis=1)
                    y_test = test_data["political_stability"]
                    feature_names = X_train.columns.tolist()

                    # Store in session state
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test
                    st.session_state.feature_names = feature_names
                    st.session_state.data_loaded = True
                    st.session_state.workflow_step = 1
                    progress_bar.progress(100)

                    status_text.empty()
                    progress_bar.empty()

                    # Create full dataframe for EDA
                    train_df = pd.DataFrame(X_train, columns=feature_names)
                    train_df["political_stability"] = y_train
                    test_df = pd.DataFrame(X_test, columns=feature_names)
                    test_df["political_stability"] = y_test
                    df_full = pd.concat([train_df, test_df])

                    # Clear cache so Home page can reload the new data
                    st.cache_data.clear()

                    # Display results
                    st.success(" Data loaded successfully! Proceed to Action 2.")

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(" Training Samples", f"{len(X_train):,}")
                    with col2:
                        st.metric(" Test Samples", f"{len(X_test):,}")
                    with col3:
                        st.metric(" Total Samples", f"{len(df_full):,}")

                    # Exploratory Data Analysis
                    st.markdown("---")
                    st.subheader(" Exploratory Data Analysis")

                    # Statistiques descriptives
                    with st.expander(" Descriptive Statistics"):
                        st.dataframe(
                            df_full.describe().T.style.background_gradient(
                                cmap="Blues"
                            ),
                            use_container_width=True,
                        )

                    # Correlation matrix
                    with st.expander(" Correlation Matrix"):
                        # Calculate correlation matrix
                        corr_matrix = df_full.select_dtypes(include=[np.number]).corr()

                        # Create heatmap with plotly
                        fig = px.imshow(
                            corr_matrix,
                            text_auto=".2f",
                            aspect="auto",
                            color_continuous_scale="RdBu_r",
                            color_continuous_midpoint=0,
                            title="Correlation Matrix of Features",
                        )
                        fig.update_layout(height=600)
                        st.plotly_chart(fig, use_container_width=True)

                        # Highlight strong correlations
                        st.markdown("**Strong Correlations (|r| > 0.7):**")
                        strong_corr = []
                        for i in range(len(corr_matrix.columns)):
                            for j in range(i + 1, len(corr_matrix.columns)):
                                if abs(corr_matrix.iloc[i, j]) > 0.7:
                                    strong_corr.append(
                                        {
                                            "Feature 1": corr_matrix.columns[i],
                                            "Feature 2": corr_matrix.columns[j],
                                            "Correlation": corr_matrix.iloc[i, j],
                                        }
                                    )
                        if strong_corr:
                            st.dataframe(
                                pd.DataFrame(strong_corr).style.background_gradient(
                                    subset=["Correlation"],
                                    cmap="RdYlGn",
                                    vmin=-1,
                                    vmax=1,
                                ),
                                use_container_width=True,
                                hide_index=True,
                            )
                        else:
                            st.info("No strong correlations found (|r| > 0.7)")

                    # Distribution de la variable cible
                    with st.expander(" Target Variable Distribution"):
                        col1, col2 = st.columns(2)

                        with col1:
                            # Histogram
                            fig1 = px.histogram(
                                df_full,
                                x="political_stability",
                                nbins=50,
                                title="Distribution of Political Stability",
                                labels={
                                    "political_stability": "Political Stability Score"
                                },
                                color_discrete_sequence=["steelblue"],
                            )
                            fig1.add_vline(
                                x=df_full["political_stability"].mean(),
                                line_dash="dash",
                                line_color="red",
                                annotation_text="Mean",
                            )
                            fig1.update_layout(height=400)
                            st.plotly_chart(fig1, use_container_width=True)

                        with col2:
                            # Box plot
                            fig2 = px.box(
                                df_full,
                                y="political_stability",
                                title="Box Plot of Political Stability",
                                labels={
                                    "political_stability": "Political Stability Score"
                                },
                                color_discrete_sequence=["lightcoral"],
                            )
                            fig2.update_layout(height=400)
                            st.plotly_chart(fig2, use_container_width=True)

                        # Statistics
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric(
                                "Mean", f"{df_full['political_stability'].mean():.3f}"
                            )
                        with col2:
                            st.metric(
                                "Std Dev", f"{df_full['political_stability'].std():.3f}"
                            )
                        with col3:
                            st.metric(
                                "Min", f"{df_full['political_stability'].min():.3f}"
                            )
                        with col4:
                            st.metric(
                                "Max", f"{df_full['political_stability'].max():.3f}"
                            )

            except Exception as e:
                st.error(f" Error loading data: {str(e)}")
                st.exception(e)

    st.markdown("---")

    # ========================================================================
    # ACTION 2: TRAIN MODELS
    # ========================================================================

    st.markdown("## Action 2: Train ML Models")
    st.markdown(
        "Train all 7 machine learning models (Random Forest, XGBoost, Gradient Boosting, Elastic Net, SVR, KNN, MLP)."
    )

    # Check if data is loaded
    if not st.session_state.data_loaded:
        st.warning(" Please complete Action 1 (Data Preparation) first!")
        st.button(
            " Train All Models",
            key="train_models",
            use_container_width=True,
            disabled=True,
        )
    else:
        if st.button(" Train All Models", key="train_models", use_container_width=True):
            with st.spinner("Training models..."):
                try:
                    import time

                    from src.models import (
                        ElasticNetPredictor,
                        GradientBoostingPredictor,
                        KNNPredictor,
                        MLPPredictor,
                        RandomForestPredictor,
                        SVRPredictor,
                        XGBoostPredictor,
                    )

                    # Get data from session state
                    status_text = st.empty()
                    status_text.text(" Getting data from session...")
                    X_train = st.session_state.X_train
                    X_test = st.session_state.X_test
                    y_train = st.session_state.y_train
                    y_test = st.session_state.y_test

                    # Define models - Use classes from src/models.py directly
                    # Each model has its own default param_grid defined in src/models.py
                    # Same 7 ML models as in main.py
                    models = [
                        ("Random Forest", RandomForestPredictor(None)),
                        ("XGBoost", XGBoostPredictor(None)),
                        ("Gradient Boosting", GradientBoostingPredictor(None)),
                        ("Elastic Net", ElasticNetPredictor(None)),
                        ("SVR", SVRPredictor(None)),
                        ("KNN", KNNPredictor(None)),
                        ("MLP", MLPPredictor(None)),
                    ]

                    results = []
                    progress_bar = st.progress(0)
                    trained_models = {}

                    # Train each model using default param_grid from src/models.py
                    for i, (model_name, model) in enumerate(models, 1):
                        status_text.text(
                            f" [{i}/{len(models)}] Training {model_name}..."
                        )

                        # Use model's default param_grid (defined in src/models.py)
                        # Suppress stdout/stderr to prevent I/O errors in Streamlit
                        with suppress_stdout_stderr():
                            model.fit(
                                X_train,
                                y_train,
                                param_grid=None,  # Uses default from src/models.py
                                cv=3,  # 3-fold instead of 5-fold for speed
                                n_jobs=1,  # Sequential to avoid BrokenPipeError
                            )

                        # Evaluate
                        metrics = model.evaluate(X_test, y_test)

                        # Store in session state
                        trained_models[model_name] = model

                        results.append(
                            {
                                "Model": model_name,
                                "R^2 Score": metrics["r2"],
                                "RMSE": metrics["rmse"],
                                "MAE": metrics["mae"],
                                "Status": " Trained",
                            }
                        )

                        progress_bar.progress(i / len(models))
                        time.sleep(0.3)

                    # Store models and results in session state
                    st.session_state.trained_models = trained_models
                    st.session_state.training_results = pd.DataFrame(results)
                    st.session_state.models_trained = True
                    st.session_state.workflow_step = 2

                    status_text.empty()
                    progress_bar.empty()

                    # Display results
                    results_df = st.session_state.training_results
                    st.success(
                        f" All {len(models)} models trained successfully! Proceed to Action 3."
                    )

                    st.subheader(" Model Performance")
                    st.dataframe(
                        results_df.style.background_gradient(
                            subset=["R^2 Score"], cmap="Greens"
                        ).format(
                            {"R^2 Score": "{:.4f}", "RMSE": "{:.4f}", "MAE": "{:.4f}"}
                        ),
                        use_container_width=True,
                        hide_index=True,
                    )

                    # Best model
                    best_model = results_df.loc[results_df["R^2 Score"].idxmax()]
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(" Best Model", best_model["Model"])
                    with col2:
                        st.metric(" R^2 Score", f"{best_model['R^2 Score']:.4f}")
                    with col3:
                        st.metric(" RMSE", f"{best_model['RMSE']:.4f}")

                    # Interactive charts
                    st.markdown("---")
                    st.subheader(" Performance Comparison")

                    col1, col2 = st.columns(2)

                    with col1:
                        # R^2 Score comparison
                        fig1 = px.bar(
                            results_df,
                            x="Model",
                            y="R^2 Score",
                            title="R^2 Score by Model",
                            color="R^2 Score",
                            color_continuous_scale="Blues",
                            text="R^2 Score",
                        )
                        fig1.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig1.update_layout(height=400, showlegend=False)
                        st.plotly_chart(fig1, use_container_width=True)

                    with col2:
                        # RMSE comparison
                        fig2 = px.bar(
                            results_df,
                            x="Model",
                            y="RMSE",
                            title="RMSE by Model",
                            color="RMSE",
                            color_continuous_scale="Reds_r",
                            text="RMSE",
                        )
                        fig2.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig2.update_layout(height=400, showlegend=False)
                        st.plotly_chart(fig2, use_container_width=True)

                except Exception as e:
                    st.error(f" Error during model training: {str(e)}")
                    st.exception(e)

    st.markdown("---")

    # ========================================================================
    # ACTION 3: TEST MODELS
    # ========================================================================

    st.markdown("## Action 3: Test Models")
    st.markdown("Test all trained models on the test set.")

    # Check if models are trained
    if not st.session_state.models_trained:
        st.warning(" Please complete Action 2 (Train Models) first!")
        st.button(
            " Test All Models",
            key="test_models",
            use_container_width=True,
            disabled=True,
        )
    else:
        if st.button(" Test All Models", key="test_models", use_container_width=True):
            with st.spinner("Testing models..."):
                try:
                    import time

                    from sklearn.metrics import (
                        mean_absolute_error,
                        mean_squared_error,
                        r2_score,
                    )

                    # Get data and models from session state
                    status_text = st.empty()
                    status_text.text(" Getting data and models from session...")
                    X_test = st.session_state.X_test
                    y_test = st.session_state.y_test
                    trained_models = st.session_state.trained_models

                    if not trained_models:
                        st.warning(
                            " No trained models found in session. Please train models first (Action 2)."
                        )
                    else:
                        results = []
                        predictions = {}
                        progress_bar = st.progress(0)

                        for i, (model_name, model) in enumerate(
                            trained_models.items(), 1
                        ):
                            status_text.text(
                                f"[{i}/{len(trained_models)}] Testing {model_name}..."
                            )

                            # Predict
                            y_pred = model.predict(X_test)

                            # Store predictions for visualization
                            predictions[model_name] = y_pred

                            # Calculate metrics
                            r2 = r2_score(y_test, y_pred)
                            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                            mae = mean_absolute_error(y_test, y_pred)

                            results.append(
                                {
                                    "Model": model_name,
                                    "R^2 Score": r2,
                                    "RMSE": rmse,
                                    "MAE": mae,
                                    "Test Samples": len(y_test),
                                }
                            )

                            progress_bar.progress(i / len(trained_models))
                            time.sleep(0.2)

                        # Store results and predictions in session state
                        st.session_state.test_results = pd.DataFrame(results)
                        st.session_state.predictions = predictions
                        st.session_state.models_tested = True
                        st.session_state.workflow_step = 3

                        status_text.empty()
                        progress_bar.empty()

                        # Display results
                        results_df = st.session_state.test_results
                        st.success(
                            f" All {len(trained_models)} models tested successfully! Proceed to Action 5."
                        )

                    st.subheader(" Test Results")
                    st.dataframe(
                        results_df.style.background_gradient(
                            subset=["R^2 Score"], cmap="Greens"
                        ).format(
                            {"R^2 Score": "{:.4f}", "RMSE": "{:.4f}", "MAE": "{:.4f}"}
                        ),
                        use_container_width=True,
                        hide_index=True,
                    )

                    # Interactive comparison charts
                    st.markdown("---")
                    st.subheader(" Performance Comparison")

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        # R^2 Score
                        fig1 = px.bar(
                            results_df.sort_values("R^2 Score", ascending=False),
                            x="Model",
                            y="R^2 Score",
                            title="R^2 Score Comparison",
                            color="R^2 Score",
                            color_continuous_scale="Greens",
                            text="R^2 Score",
                        )
                        fig1.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig1.update_layout(height=400, showlegend=False)
                        st.plotly_chart(fig1, use_container_width=True)

                    with col2:
                        # RMSE
                        fig2 = px.bar(
                            results_df.sort_values("RMSE"),
                            x="Model",
                            y="RMSE",
                            title="RMSE Comparison",
                            color="RMSE",
                            color_continuous_scale="Reds_r",
                            text="RMSE",
                        )
                        fig2.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig2.update_layout(height=400, showlegend=False)
                        st.plotly_chart(fig2, use_container_width=True)

                    with col3:
                        # MAE
                        fig3 = px.bar(
                            results_df.sort_values("MAE"),
                            x="Model",
                            y="MAE",
                            title="MAE Comparison",
                            color="MAE",
                            color_continuous_scale="Oranges_r",
                            text="MAE",
                        )
                        fig3.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig3.update_layout(height=400, showlegend=False)
                        st.plotly_chart(fig3, use_container_width=True)

                except Exception as e:
                    st.error(f" Error during model testing: {str(e)}")
                    st.exception(e)

    st.markdown("---")

    # ========================================================================
    # ACTION 4: EVALUATE MODELS
    # ========================================================================

    st.markdown("##  Action 4: Evaluate Saved Models")
    st.markdown("View and compare all saved model results.")

    if st.button(
        " Evaluate All Models", key="evaluate_models", use_container_width=True
    ):
        with st.spinner("Evaluating models..."):
            try:
                paths = get_project_paths()
                results_dir = paths["results"]

                # Check for result files (fixed filenames)
                benchmark_file = results_dir / "benchmark_results.csv"
                test_file = results_dir / "test_results.csv"

                if not benchmark_file.exists() and not test_file.exists():
                    st.warning(
                        " No result files found. Please train or test models first."
                    )
                else:
                    # Load and combine all results
                    all_results = []

                    if benchmark_file.exists():
                        st.subheader(" Benchmark Results")
                        df = pd.read_csv(benchmark_file)
                        df["Source"] = "Training (Benchmark)"
                        all_results.append(df)
                        st.dataframe(df, use_container_width=True, hide_index=True)

                    if test_file.exists():
                        st.subheader(" Test Results")
                        df = pd.read_csv(test_file)
                        df["Source"] = "Test Set"
                        all_results.append(df)
                        st.dataframe(df, use_container_width=True, hide_index=True)

                    # Create comprehensive summary
                    if all_results:
                        combined_df = pd.concat(all_results, ignore_index=True)

                        # Save summary (fixed filename, overwrites previous)
                        summary_file = results_dir / "evaluation_summary.csv"
                        combined_df.to_csv(summary_file, index=False)

                        st.markdown("---")
                        st.subheader(" Comprehensive Summary")
                        st.dataframe(
                            combined_df, use_container_width=True, hide_index=True
                        )

                        # Download button
                        st.markdown("####  Download Summary")
                        from datetime import datetime

                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        st.download_button(
                            " Download Evaluation Summary",
                            combined_df.to_csv(index=False).encode("utf-8"),
                            f"evaluation_summary_{timestamp}.csv",
                            "text/csv",
                            key="download-evaluation",
                        )

            except Exception as e:
                st.error(f" Error during model evaluation: {str(e)}")
                st.exception(e)

    st.markdown("---")

    # ========================================================================
    # ACTION 5: GENERATE VISUALIZATIONS
    # ========================================================================

    st.markdown("##  Action 5: Generate Visualizations")
    st.markdown("View comprehensive model performance comparisons and predictions.")

    # Check if models are tested
    if not st.session_state.models_tested:
        st.warning(" Please complete Action 3 (Test Models) first!")
        st.button(
            " Generate All Visualizations",
            key="visualizations",
            use_container_width=True,
            disabled=True,
        )
    else:
        if st.button(
            " Generate All Visualizations",
            key="visualizations",
            use_container_width=True,
        ):
            with st.spinner("Generating visualizations..."):
                try:
                    # Get data from session state
                    status_text = st.empty()
                    status_text.text(" Loading results from session...")

                    test_results = st.session_state.test_results
                    predictions = st.session_state.predictions
                    y_test = st.session_state.y_test
                    trained_models = st.session_state.trained_models
                    feature_names = st.session_state.feature_names

                    status_text.empty()

                    # Display results
                    st.success(" Visualizations generated successfully!")

                    # 1. Performance Summary Table
                    st.markdown("---")
                    st.subheader(" Model Performance Summary")
                    st.dataframe(
                        test_results.style.background_gradient(
                            subset=["R^2 Score"], cmap="Greens"
                        )
                        .background_gradient(subset=["RMSE"], cmap="Reds_r")
                        .background_gradient(subset=["MAE"], cmap="Oranges_r")
                        .format(
                            {"R^2 Score": "{:.4f}", "RMSE": "{:.4f}", "MAE": "{:.4f}"}
                        ),
                        use_container_width=True,
                        hide_index=True,
                    )

                    # Best and worst models
                    col1, col2, col3, col4 = st.columns(4)
                    best_model = test_results.loc[test_results["R^2 Score"].idxmax()]
                    worst_model = test_results.loc[test_results["R^2 Score"].idxmin()]

                    with col1:
                        st.metric(" Best Model", best_model["Model"])
                    with col2:
                        st.metric(" Best R^2", f"{best_model['R^2 Score']:.4f}")
                    with col3:
                        st.metric(" Lowest RMSE", f"{test_results['RMSE'].min():.4f}")
                    with col4:
                        st.metric(" Lowest MAE", f"{test_results['MAE'].min():.4f}")

                    # 2. Interactive Performance Comparison Charts
                    st.markdown("---")
                    st.subheader(" Interactive Performance Comparison")

                    col1, col2 = st.columns(2)

                    with col1:
                        # R^2 Score comparison
                        fig1 = px.bar(
                            test_results.sort_values("R^2 Score", ascending=False),
                            x="Model",
                            y="R^2 Score",
                            title="R^2 Score by Model",
                            color="R^2 Score",
                            color_continuous_scale="Greens",
                            text="R^2 Score",
                        )
                        fig1.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig1.update_layout(height=400)
                        st.plotly_chart(fig1, use_container_width=True)

                        # MAE comparison
                        fig3 = px.bar(
                            test_results.sort_values("MAE"),
                            x="Model",
                            y="MAE",
                            title="Mean Absolute Error by Model",
                            color="MAE",
                            color_continuous_scale="Oranges_r",
                            text="MAE",
                        )
                        fig3.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig3.update_layout(height=400)
                        st.plotly_chart(fig3, use_container_width=True)

                    with col2:
                        # RMSE comparison
                        fig2 = px.bar(
                            test_results.sort_values("RMSE"),
                            x="Model",
                            y="RMSE",
                            title="Root Mean Squared Error by Model",
                            color="RMSE",
                            color_continuous_scale="Reds_r",
                            text="RMSE",
                        )
                        fig2.update_traces(
                            texttemplate="%{text:.4f}", textposition="outside"
                        )
                        fig2.update_layout(height=400)
                        st.plotly_chart(fig2, use_container_width=True)

                        # All metrics radar chart
                        fig4 = go.Figure()

                        for _, row in test_results.iterrows():
                            fig4.add_trace(
                                go.Scatterpolar(
                                    r=[
                                        row["R^2 Score"],
                                        1 - row["RMSE"],
                                        1 - row["MAE"],
                                    ],
                                    theta=["R^2 Score", "RMSE (inv)", "MAE (inv)"],
                                    fill="toself",
                                    name=row["Model"],
                                )
                            )

                        fig4.update_layout(
                            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                            title="Model Performance Radar Chart",
                            height=400,
                        )
                        st.plotly_chart(fig4, use_container_width=True)

                    # 3. Predictions vs Actual
                    st.markdown("---")
                    st.subheader(" Predictions vs Actual Values")

                    # Create subplot for each model
                    n_models = len(predictions)
                    cols_per_row = 2
                    n_rows = (n_models + cols_per_row - 1) // cols_per_row

                    for i in range(0, n_models, cols_per_row):
                        cols = st.columns(cols_per_row)
                        for j, col in enumerate(cols):
                            if i + j < n_models:
                                model_name = list(predictions.keys())[i + j]
                                y_pred = predictions[model_name]
                                r2 = test_results[test_results["Model"] == model_name][
                                    "R^2 Score"
                                ].values[0]

                                with col:
                                    fig = go.Figure()

                                    # Scatter plot
                                    fig.add_trace(
                                        go.Scatter(
                                            x=y_test,
                                            y=y_pred,
                                            mode="markers",
                                            name="Predictions",
                                            marker=dict(
                                                size=6, opacity=0.6, color="steelblue"
                                            ),
                                        )
                                    )

                                    # Perfect prediction line
                                    min_val = min(y_test.min(), y_pred.min())
                                    max_val = max(y_test.max(), y_pred.max())
                                    fig.add_trace(
                                        go.Scatter(
                                            x=[min_val, max_val],
                                            y=[min_val, max_val],
                                            mode="lines",
                                            name="Perfect Prediction",
                                            line=dict(
                                                color="red", dash="dash", width=2
                                            ),
                                        )
                                    )

                                    fig.update_layout(
                                        title=f"{model_name}<br>R^2 = {r2:.4f}",
                                        xaxis_title="Actual Values",
                                        yaxis_title="Predicted Values",
                                        height=400,
                                        showlegend=True,
                                    )

                                    st.plotly_chart(fig, use_container_width=True)

                    # 4. Feature Importance (for best model)
                    st.markdown("---")
                    st.subheader(" Feature Importance Analysis")

                    best_model_name = test_results.loc[
                        test_results["R^2 Score"].idxmax(), "Model"
                    ]
                    best_model = trained_models[best_model_name]

                    if hasattr(best_model.model, "feature_importances_"):
                        importances = best_model.model.feature_importances_
                        importance_df = (
                            pd.DataFrame(
                                {"Feature": feature_names, "Importance": importances}
                            )
                            .sort_values("Importance", ascending=False)
                            .head(15)
                        )

                        # Table
                        st.markdown(
                            f"**Top 15 Most Important Features ({best_model_name})**"
                        )
                        st.dataframe(
                            importance_df.style.background_gradient(
                                subset=["Importance"], cmap="Blues"
                            ).format({"Importance": "{:.4f}"}),
                            use_container_width=True,
                            hide_index=True,
                        )

                        # Interactive bar chart
                        fig = px.bar(
                            importance_df,
                            x="Importance",
                            y="Feature",
                            orientation="h",
                            title=f"Feature Importance - {best_model_name}",
                            color="Importance",
                            color_continuous_scale="Blues",
                        )
                        fig.update_layout(
                            height=500, yaxis={"categoryorder": "total ascending"}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info(
                            f"Feature importance not available for {best_model_name}"
                        )

                    # 5. Error Distribution Analysis
                    st.markdown("---")
                    st.subheader(" Error Distribution Analysis")

                    error_data = []
                    for model_name, y_pred in predictions.items():
                        errors = y_test - y_pred
                        for error in errors:
                            error_data.append({"Model": model_name, "Error": error})

                    error_df = pd.DataFrame(error_data)

                    # Box plot of errors
                    fig = px.box(
                        error_df,
                        x="Model",
                        y="Error",
                        title="Error Distribution by Model",
                        color="Model",
                        points="outliers",
                    )
                    fig.update_layout(height=500, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)

                    # Error statistics table
                    st.markdown("**Error Statistics by Model**")
                    error_stats = (
                        error_df.groupby("Model")["Error"]
                        .agg(
                            [
                                ("Mean Error", "mean"),
                                ("Std Dev", "std"),
                                ("Min Error", "min"),
                                ("Max Error", "max"),
                                ("Median Error", "median"),
                            ]
                        )
                        .reset_index()
                    )

                    st.dataframe(
                        error_stats.style.background_gradient(
                            subset=["Mean Error"], cmap="RdYlGn_r", vmin=-1, vmax=1
                        ).format(
                            {
                                col: "{:.4f}"
                                for col in error_stats.columns
                                if col != "Model"
                            }
                        ),
                        use_container_width=True,
                        hide_index=True,
                    )

                except Exception as e:
                    st.error(f" Error generating visualizations: {str(e)}")
                    st.exception(e)

# ============================================================================
# FOOTER
# ============================================================================

st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: gray; padding: 2rem 0;'>
    <p><b>Political Stability Observatory</b> | Master's Project 2025-2026</p>
    <p>Data Science & Advanced Programming | Machine Learning Analysis</p>
    <p>Dataset: World Bank, UNDP (1996-2023) | 166 Countries | 5 ML Models</p>
</div>
""",
    unsafe_allow_html=True,
)
